{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:02:19.072238Z",
     "start_time": "2023-09-24T19:02:15.829529Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import nltk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def conv_to_char(n):\n",
    "    s = list(n)\n",
    "    st = \"\"\n",
    "    for i in s:\n",
    "        st += chr(i)\n",
    "    return st"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:02:19.072745Z",
     "start_time": "2023-09-24T19:02:19.066022Z"
    }
   },
   "id": "9ca83876c541b81f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def features_of_images_train_val(location_folder):\n",
    "    \n",
    "    list_of_files = os.listdir(location_folder)\n",
    "    \n",
    "    full_file_path = []\n",
    "    for i in list_of_files:\n",
    "        full_file_path.append(location_folder+i)\n",
    "\n",
    "    id = []\n",
    "    cls = []\n",
    "    image = []\n",
    "\n",
    "    for i in full_file_path:\n",
    "        raw_img = tf.data.TFRecordDataset(i)\n",
    "        image_description = {\n",
    "            \"id\" : tf.io.FixedLenFeature([],tf.string),\n",
    "            \"class\": tf.io.FixedLenFeature([],tf.int64),\n",
    "            \"image\": tf.io.FixedLenFeature([],tf.string)\n",
    "        }\n",
    "        y = lambda x: tf.io.parse_single_example(x,image_description)\n",
    "        img = raw_img.map(y)\n",
    "\n",
    "        begin = i.rindex(\"-\")+1\n",
    "        end = i.index(\".tfrec\")\n",
    "        num = int(i[begin:end])\n",
    "\n",
    "        for dr in img.take(num):\n",
    "            id.append(conv_to_char(dr[\"id\"].numpy()))\n",
    "            cls.append(int(dr[\"class\"].numpy()))\n",
    "            image.append(tf.io.decode_image(dr[\"image\"]).numpy())\n",
    "    \n",
    "    return id,cls,image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:02:20.648359Z",
     "start_time": "2023-09-24T19:02:20.637345Z"
    }
   },
   "id": "b25c944d65b47cd"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def features_of_images_test(location_folder):\n",
    "\n",
    "    list_of_files = os.listdir(location_folder)\n",
    "\n",
    "    full_file_path = []\n",
    "    for i in list_of_files:\n",
    "        full_file_path.append(location_folder+i)\n",
    "\n",
    "    id = []\n",
    "    image = []\n",
    "\n",
    "    for i in full_file_path:\n",
    "        raw_img = tf.data.TFRecordDataset(i)\n",
    "        image_description = {\n",
    "            \"id\" : tf.io.FixedLenFeature([],tf.string),\n",
    "            \"image\": tf.io.FixedLenFeature([],tf.string)\n",
    "        }\n",
    "        y = lambda x: tf.io.parse_single_example(x,image_description)\n",
    "        img = raw_img.map(y)\n",
    "\n",
    "        begin = i.rindex(\"-\")+1\n",
    "        end = i.index(\".tfrec\")\n",
    "        num = int(i[begin:end])\n",
    "\n",
    "        for dr in img.take(num):\n",
    "            id.append(conv_to_char(dr[\"id\"].numpy()))\n",
    "            image.append(tf.io.decode_image(dr[\"image\"]).numpy())\n",
    "\n",
    "    return id,image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:02:21.195802Z",
     "start_time": "2023-09-24T19:02:21.189792Z"
    }
   },
   "id": "a3368db50e46ca11"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "location_folder_train_192 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-192x192/train/\"\n",
    "\n",
    "location_folder_train_224 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-224x224/train/\"\n",
    "\n",
    "location_folder_train_331 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-331x331/train/\"\n",
    "\n",
    "location_folder_train_512 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-512x512/train/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:02:21.821092Z",
     "start_time": "2023-09-24T19:02:21.817861Z"
    }
   },
   "id": "9023735b9f7670c6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "location_folder_val_192 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-192x192/val/\"\n",
    "\n",
    "location_folder_val_224 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-224x224/val/\"\n",
    "\n",
    "location_folder_val_331 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-331x331/val/\"\n",
    "\n",
    "location_folder_val_512 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-512x512/val/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:02:22.309033Z",
     "start_time": "2023-09-24T19:02:22.304531Z"
    }
   },
   "id": "f5e6cfc358f4a77"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "location_folder_test_192 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-192x192/test/\"\n",
    "\n",
    "location_folder_test_224 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-224x224/test/\"\n",
    "\n",
    "location_folder_test_331 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-331x331/test/\"\n",
    "\n",
    "location_folder_test_512 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-512x512/test/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:02:22.956664Z",
     "start_time": "2023-09-24T19:02:22.953645Z"
    }
   },
   "id": "39bffd3f10463c88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trainign Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f2a0063f9f7b8c0"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "id_train_192,cls_train_192,image_train_192 = features_of_images_train_val(location_folder_train_192)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:02:30.164448Z",
     "start_time": "2023-09-24T19:02:23.753155Z"
    }
   },
   "id": "b51c6c0efac0912"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "id_train_224,cls_train_224,image_train_224 = features_of_images_train_val(location_folder_train_224)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:02:37.399351Z",
     "start_time": "2023-09-24T19:02:30.164816Z"
    }
   },
   "id": "cb6c0a694edd9ed0"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "id_train_331,cls_train_331,image_train_331 = features_of_images_train_val(location_folder_train_331)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:02:51.675311Z",
     "start_time": "2023-09-24T19:02:37.403310Z"
    }
   },
   "id": "82e73154eb98995"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "id_train_512,cls_train_512,image_train_512 = features_of_images_train_val(location_folder_train_512)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:03:20.377128Z",
     "start_time": "2023-09-24T19:02:51.677245Z"
    }
   },
   "id": "6c6ec45f3090140a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validation Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c77cd770ad4c213c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "id_val_192,cls_val_192,image_val_192 = features_of_images_train_val(location_folder_val_192)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:03:29.162697Z",
     "start_time": "2023-09-24T19:03:25.752702Z"
    }
   },
   "id": "2893568b5f0d1b19"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "id_val_224,cls_val_224,image_val_224 = features_of_images_train_val(location_folder_val_224)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:03:31.960006Z",
     "start_time": "2023-09-24T19:03:28.923451Z"
    }
   },
   "id": "eff51226d3f27372"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "id_val_331,cls_val_331,image_val_331 = features_of_images_train_val(location_folder_val_331)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:03:36.515257Z",
     "start_time": "2023-09-24T19:03:31.967306Z"
    }
   },
   "id": "3d56b309b82d5a32"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "id_val_512,cls_val_512,image_val_512 = features_of_images_train_val(location_folder_val_512)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:03:44.838795Z",
     "start_time": "2023-09-24T19:03:36.543677Z"
    }
   },
   "id": "6e07ee7389e39101"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "253fb48bdc122624"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "id_test_192,image_test_192 = features_of_images_test(location_folder_test_192)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:03:49.147977Z",
     "start_time": "2023-09-24T19:03:44.865235Z"
    }
   },
   "id": "efa4607c16654399"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "id_test_224,image_test_224 = features_of_images_test(location_folder_test_224)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:03:53.525168Z",
     "start_time": "2023-09-24T19:03:49.152639Z"
    }
   },
   "id": "e3fd18687173966c"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "id_test_331,image_test_331 = features_of_images_test(location_folder_test_331)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:04:01.376497Z",
     "start_time": "2023-09-24T19:03:53.537481Z"
    }
   },
   "id": "2cb7fe228dd537db"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "id_test_512,image_test_512 = features_of_images_test(location_folder_test_512)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:04:18.990363Z",
     "start_time": "2023-09-24T19:04:01.406260Z"
    }
   },
   "id": "3a3294508d3ce712"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_train_192_mod = np.array(id_train_192)\n",
    "cls_train_192_mod = np.array(cls_train_192)\n",
    "image_train_192_mod = np.array(image_train_192)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "46c673117c9f41af"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_train_224_mod = np.array(id_train_224)\n",
    "cls_train_224_mod = np.array(cls_train_224)\n",
    "image_train_224_mod = np.array(image_train_224)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "8bf01f83f9878f3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_train_331_mod = np.array(id_train_331)\n",
    "cls_train_331_mod = np.array(cls_train_331)\n",
    "image_train_331_mod = np.array(image_train_331)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6e1dd46e75025bc2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_train_512_mod = np.array(id_train_512)\n",
    "cls_train_512_mod = np.array(cls_train_512)\n",
    "image_train_512_mod = np.array(image_train_512)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "248791b91077fb0d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_val_192_mod = np.array(id_val_192)\n",
    "cls_val_192_mod = np.array(cls_val_192)\n",
    "image_val_192_mod = np.array(image_val_192)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b354554400120862"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_val_224_mod = np.array(id_val_224)\n",
    "cls_val_224_mod = np.array(cls_val_224)\n",
    "image_val_224_mod = np.array(image_val_224)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46ec752e87ac0883"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_val_331_mod = np.array(id_val_331)\n",
    "cls_val_331_mod = np.array(cls_val_331)\n",
    "image_val_331_mod = np.array(image_val_331)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "244d6980698b7c1a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_val_512_mod = np.array(id_val_512)\n",
    "cls_val_512_mod = np.array(cls_val_512)\n",
    "image_val_512_mod = np.array(image_val_512)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fad3b76e2331aa0a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_test_192_mod = np.array(id_test_192)\n",
    "image_test_192_mod = np.array(image_test_192)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13818742f1ebd907"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_test_224_mod = np.array(id_test_224)\n",
    "image_test_224_mod = np.array(image_test_224)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e4552c44476a3f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_test_331_mod = np.array(id_test_331)\n",
    "image_test_331_mod = np.array(image_test_331)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2e393648ca9961b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_test_512_mod = np.array(id_test_512)\n",
    "image_test_512_mod = np.array(image_test_512)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82ca02e8d0cc0c3f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
