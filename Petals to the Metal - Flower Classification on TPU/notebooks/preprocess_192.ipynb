{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:34:33.377551Z",
     "start_time": "2023-09-24T19:34:28.022569Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import nltk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def conv_to_char(n):\n",
    "    s = list(n)\n",
    "    st = \"\"\n",
    "    for i in s:\n",
    "        st += chr(i)\n",
    "    return st"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:34:33.379685Z",
     "start_time": "2023-09-24T19:34:33.377079Z"
    }
   },
   "id": "9ca83876c541b81f"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def features_of_images_train_val(location_folder):\n",
    "    \n",
    "    list_of_files = os.listdir(location_folder)\n",
    "    \n",
    "    full_file_path = []\n",
    "    for i in list_of_files:\n",
    "        full_file_path.append(location_folder+i)\n",
    "\n",
    "    id = []\n",
    "    cls = []\n",
    "    image = []\n",
    "\n",
    "    for i in full_file_path:\n",
    "        raw_img = tf.data.TFRecordDataset(i)\n",
    "        image_description = {\n",
    "            \"id\" : tf.io.FixedLenFeature([],tf.string),\n",
    "            \"class\": tf.io.FixedLenFeature([],tf.int64),\n",
    "            \"image\": tf.io.FixedLenFeature([],tf.string)\n",
    "        }\n",
    "        y = lambda x: tf.io.parse_single_example(x,image_description)\n",
    "        img = raw_img.map(y)\n",
    "\n",
    "        begin = i.rindex(\"-\")+1\n",
    "        end = i.index(\".tfrec\")\n",
    "        num = int(i[begin:end])\n",
    "\n",
    "        for dr in img.take(num):\n",
    "            id.append(conv_to_char(dr[\"id\"].numpy()))\n",
    "            cls.append(int(dr[\"class\"].numpy()))\n",
    "            image.append(tf.io.decode_image(dr[\"image\"]).numpy())\n",
    "    \n",
    "    id = np.array(id)\n",
    "    cls = np.array(cls)\n",
    "    image = np.array(image)\n",
    "    \n",
    "    return id,cls,image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:35:53.561238Z",
     "start_time": "2023-09-24T19:35:53.556277Z"
    }
   },
   "id": "b25c944d65b47cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def features_of_images_test(location_folder):\n",
    "\n",
    "    list_of_files = os.listdir(location_folder)\n",
    "\n",
    "    full_file_path = []\n",
    "    for i in list_of_files:\n",
    "        full_file_path.append(location_folder+i)\n",
    "\n",
    "    id = []\n",
    "    image = []\n",
    "\n",
    "    for i in full_file_path:\n",
    "        raw_img = tf.data.TFRecordDataset(i)\n",
    "        image_description = {\n",
    "            \"id\" : tf.io.FixedLenFeature([],tf.string),\n",
    "            \"image\": tf.io.FixedLenFeature([],tf.string)\n",
    "        }\n",
    "        y = lambda x: tf.io.parse_single_example(x,image_description)\n",
    "        img = raw_img.map(y)\n",
    "\n",
    "        begin = i.rindex(\"-\")+1\n",
    "        end = i.index(\".tfrec\")\n",
    "        num = int(i[begin:end])\n",
    "\n",
    "        for dr in img.take(num):\n",
    "            id.append(conv_to_char(dr[\"id\"].numpy()))\n",
    "            image.append(tf.io.decode_image(dr[\"image\"]).numpy())\n",
    "\n",
    "    id = np.array(id)\n",
    "    image = np.array(image)\n",
    "    \n",
    "    return id,image"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a3368db50e46ca11"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "location_folder_train_192 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-192x192/train/\"\n",
    "\n",
    "location_folder_train_224 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-224x224/train/\"\n",
    "\n",
    "location_folder_train_331 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-331x331/train/\"\n",
    "\n",
    "location_folder_train_512 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-512x512/train/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:35:54.942044Z",
     "start_time": "2023-09-24T19:35:54.926180Z"
    }
   },
   "id": "9023735b9f7670c6"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "location_folder_val_192 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-192x192/val/\"\n",
    "\n",
    "location_folder_val_224 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-224x224/val/\"\n",
    "\n",
    "location_folder_val_331 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-331x331/val/\"\n",
    "\n",
    "location_folder_val_512 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-512x512/val/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:35:55.292001Z",
     "start_time": "2023-09-24T19:35:55.283934Z"
    }
   },
   "id": "f5e6cfc358f4a77"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "location_folder_test_192 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-192x192/test/\"\n",
    "\n",
    "location_folder_test_224 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-224x224/test/\"\n",
    "\n",
    "location_folder_test_331 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-331x331/test/\"\n",
    "\n",
    "location_folder_test_512 = \"/Users/amith/Documents/GitHub/kaggle/Petals to the Metal - Flower Classification on TPU/tpu-getting-started/tfrecords-jpeg-512x512/test/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:35:55.841416Z",
     "start_time": "2023-09-24T19:35:55.834445Z"
    }
   },
   "id": "39bffd3f10463c88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trainign Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f2a0063f9f7b8c0"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "id_train_192,cls_train_192,image_train_192 = features_of_images_train_val(location_folder_train_192)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:36:04.237598Z",
     "start_time": "2023-09-24T19:35:56.869530Z"
    }
   },
   "id": "b51c6c0efac0912"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "id_train_224,cls_train_224,image_train_224 = features_of_images_train_val(location_folder_train_224)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:36:12.812277Z",
     "start_time": "2023-09-24T19:36:04.239091Z"
    }
   },
   "id": "cb6c0a694edd9ed0"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "id_train_331,cls_train_331,image_train_331 = features_of_images_train_val(location_folder_train_331)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-24T19:36:56.850890Z",
     "start_time": "2023-09-24T19:36:12.816910Z"
    }
   },
   "id": "82e73154eb98995"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_train_512,cls_train_512,image_train_512 = features_of_images_train_val(location_folder_train_512)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-24T19:36:56.847704Z"
    }
   },
   "id": "6c6ec45f3090140a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validation Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c77cd770ad4c213c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_val_192,cls_val_192,image_val_192 = features_of_images_train_val(location_folder_val_192)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2893568b5f0d1b19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_val_224,cls_val_224,image_val_224 = features_of_images_train_val(location_folder_val_224)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "eff51226d3f27372"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_val_331,cls_val_331,image_val_331 = features_of_images_train_val(location_folder_val_331)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3d56b309b82d5a32"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_val_512,cls_val_512,image_val_512 = features_of_images_train_val(location_folder_val_512)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6e07ee7389e39101"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "253fb48bdc122624"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_test_192,image_test_192 = features_of_images_test(location_folder_test_192)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "efa4607c16654399"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_test_224,image_test_224 = features_of_images_test(location_folder_test_224)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e3fd18687173966c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_test_331,image_test_331 = features_of_images_test(location_folder_test_331)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2cb7fe228dd537db"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "id_test_512,image_test_512 = features_of_images_test(location_folder_test_512)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3a3294508d3ce712"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "21aecb1ca6ea180f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
