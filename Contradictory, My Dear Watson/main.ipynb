{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Contradictory, My Dear Watson\n",
    "\n",
    "### Detecting contradiction and entailment in multilingual text using TPUs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59d541bc66e63c98"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Kaggle link:** https://www.kaggle.com/competitions/contradictory-my-dear-watson/overview"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a22670659a9ff77"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Description\n",
    "\n",
    "\"…when you have eliminated the impossible, whatever remains, however improbable, must be the truth\"\n",
    "-Sir Arthur Conan Doyle\n",
    "\n",
    "Our brains process the meaning of a sentence like this rather quickly.\n",
    "\n",
    "We're able to surmise:\n",
    "\n",
    "Some things to be true: \"You can find the right answer through the process of elimination.”\n",
    "Others that may have truth: \"Ideas that are improbable are not impossible!\"\n",
    "And some claims are clearly contradictory: \"Things that you have ruled out as impossible are where the truth lies.\"\n",
    "Natural language processing (NLP) has grown increasingly elaborate over the past few years. Machine learning models tackle question answering, text extraction, sentence generation, and many other complex tasks. But, can machines determine the relationships between sentences, or is that still left to humans? If NLP can be applied between sentences, this could have profound implications for fact-checking, identifying fake news, analyzing text, and much more."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52416a28ac9b197c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The Challenge:\n",
    "If you have two sentences, there are three ways they could be related: one could entail the other, one could contradict the other, or they could be unrelated. Natural Language Inferencing (NLI) is a popular NLP problem that involves determining how pairs of sentences (consisting of a premise and a hypothesis) are related.\n",
    "\n",
    "Your task is to create an NLI model that assigns labels of 0, 1, or 2 (corresponding to entailment, neutral, and contradiction) to pairs of premises and hypotheses. To make things more interesting, the train and test set include text in fifteen different languages! You can find more details on the dataset by reviewing the Data page.\n",
    "\n",
    "Today, the most common approaches to NLI problems include using embeddings and transformers like BERT. In this competition, we’re providing a starter notebook to try your hand at this problem using the power of Tensor Processing Units (TPUs). TPUs are powerful hardware accelerators specialized in deep learning tasks, including Natural Language Processing. Kaggle provides all users TPU Quota at no cost, which you can use to explore this competition. Check out our TPU documentation and Kaggle’s YouTube playlist for more information and resources."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a064956c6ea3e9bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Recommended Tutorial\n",
    "We highly recommend this excellent tutorial on using KerasNLP to solve this problem, from the Keras team as well as Ana Sofia Uzsoy’s Tutorial that walks you through creating your very first submission step by step with TPUs and BERT.\n",
    "    This is a great opportunity to flex your NLP muscles and solve an exciting problem!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af6b7a6e06c01c2f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Disclaimer: \n",
    "The dataset for this competition contains text that may be considered profane, vulgar, or offensive."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32fac903b0246812"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3be63b4095596948"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Goal\n",
    "Your goal is to predict whether a given hypothesis is related to its premise by contradiction, entailment, or whether neither of those is true (neutral).\n",
    "For each sample in the test set, you must predict a 0, 1, or 2 value for the variable.\n",
    "\n",
    "Those values map to the logical condition as:\n",
    "\n",
    "0 == entailment\n",
    "1 == neutral\n",
    "2 == contradiction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8bb1cac99e749e5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Metric\n",
    "Your score is the percentage of relationships you correctly predict. This is known as accuracy.\n",
    "\n",
    "\n",
    "#### Submission File Format\n",
    "You should submit a csv file with exactly 5195 entries plus a header row. Your submission will show an error if you have extra columns (beyond id and prediction) or rows.\n",
    "\n",
    "The file should have exactly 2 columns:\n",
    "\n",
    "id (sorted in any order)\n",
    "prediction (contains your predictions: 0 for entailment, 1 for neutral, 2 for contradiction)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c3647e5d276a37c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### id,prediction\n",
    "\n",
    "c6d58c3f69,1\n",
    "cefcc82292,1\n",
    "e98005252c,1\n",
    "58518c10ba,1\n",
    "c32b0d16df,1\n",
    "Etc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a99cefeb49fb8a5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can download an example submission file (sample_submission.csv) on the Data page."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66910a2ddc895569"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Code Submission Requirement\n",
    "\n",
    "In this code competition, your submission.csv file must be generated as an output from a Kaggle notebook. For details on how to submit from a notebook, review the FAQ on \"How do I make a submission?\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c22346459928e30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset Description\n",
    "In this Getting Started Competition, we’re classifying pairs of sentences (consisting of a premise and a hypothesis) into three categories - entailment, contradiction, or neutral. Let’s take a look at an example of each of these cases for the following premise:\n",
    "\n",
    "He came, he opened the door and I remember looking back and seeing the expression on his face, and I could tell that he was disappointed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24ce866dd587bae4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hypothesis 1:\n",
    "\n",
    "Just by the look on his face when he came through the door I just knew that he was let down.\n",
    "\n",
    "We know that this is true based on the information in the premise. So, this pair is related by entailment.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42718670fdc84a38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hypothesis 2:\n",
    "\n",
    "He was trying not to make us feel guilty but we knew we had caused him trouble.\n",
    "\n",
    "This very well might be true, but we can’t conclude this based on the information in the premise. So, this relationship is neutral."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a5306ce8bb60729"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hypothesis 3:\n",
    "\n",
    "He was so excited and bursting with joy that he practically knocked the door off it's frame.\n",
    "\n",
    "We know this isn’t true, because it is the complete opposite of what the premise says. So, this pair is related by contradiction.\n",
    "\n",
    "This dataset contains premise-hypothesis pairs in fifteen different languages, including:\n",
    "Arabic, Bulgarian, Chinese, German, Greek, English, Spanish, French, Hindi, Russian, Swahili, Thai, Turkish, Urdu, and Vietnamese."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "748badb95e4b61c0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Files:\n",
    "train.csv: This file contains the ID, premise, hypothesis, and label, as well as the language of the text and its two-letter abbreviation\n",
    "\n",
    "test.csv: This file contains the ID, premise, hypothesis, language, and language abbreviation, without labels.\n",
    "\n",
    "sample_submission.csv: This is a sample submission file in the correct format:\n",
    "id: a unique identifier for each sample\n",
    "    label: the classification of the relationship between the premise and hypothesis (0 for entailment, 1 for neutral, 2 for contradiction)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d97dbcc5c79c27"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Special thanks to Tensorflow Datasets (TFDS) for providing this and many other useful datasets! For more information, visit: https://www.tensorflow.org/datasets\n",
    "\n",
    "Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e73fedea0caa12d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.linear_model import *\n",
    "from math import *\n",
    "from nltk import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from deep_translator import *\n",
    "import os\n",
    "import nltk"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-01T23:10:37.712407Z",
     "start_time": "2023-09-01T23:10:37.711994Z"
    }
   },
   "id": "c884dfeea3485054"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "28e96777a05e762f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data/train.csv\")\n",
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a3af578bf4843a99"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"data/test.csv\")\n",
    "df_test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b8c50750e8648cbb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Number of training dataset : \",len(df_train))\n",
    "print(\"Number of testing dataset  : \",len(df_test))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d50be4dd3a764c6e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df_train_1 = df_train.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-01T22:57:49.624090Z",
     "start_time": "2023-09-01T22:57:49.617700Z"
    }
   },
   "id": "a91bf364fa83f8a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
